Made a multimodal Search by using ChromaDB as a vector database, where I have used imageloaders(),OpenCLIPEmbeddingFunction() to convert the datas stored into vector embeddings. The search queryâ€™s embedding vector is then compared to the stored vectors in ChromaDB to find the most similar ones. This is typically done using cosine similarity, Euclidean distance, or other metrics that measure the closeness of vectors in the high-dimensional space. Then, the image whose embeddings are closer to query embeddings will be shown at first for effective similarity!
